{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Transformers\n",
    "In this Jupyter Lab file, we will learn how to use the Transformer for classification task. <br>\n",
    "Source: please checkout this [REPO](https://github.com/brightmart/text_classification) to learn more about different models (including this Transformers) for classification task.\n",
    "\n",
    "- TODO#1: add tensorboard to visualize training loss, computational graph.\n",
    "- TODO#2: (at home) change from the toy dataset to the real IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonvx/anaconda2/envs/ipykernel_py3_ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include *.py files from other folders\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_x: Tensor(\"input_x:0\", shape=(128, 50), dtype=int32)\n",
      "get_mask==>result: Tensor(\"mul:0\", shape=(50, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from pythonlibs.embeddings.transformers.a2_base_model import BaseClass\n",
    "from pythonlibs.embeddings.transformers.a2_encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing graph on Jupyter Notebook\n",
    "# source: https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path = '../../../my_data/tf_transformers_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Creating random dataset\n",
    "def get_unique_labels(length=5):\n",
    "    #if length is  None:\n",
    "    #    x=[2,3,4,5,6]\n",
    "    #else:\n",
    "    x=[i for i in range(2,2+length)]\n",
    "    random.shuffle(x)\n",
    "    return x\n",
    "\n",
    "def get_unique_labels_batch(batch_size,length=None):\n",
    "    x=[]\n",
    "    for i in range(batch_size):\n",
    "        labels=get_unique_labels(length=length)\n",
    "        x.append(labels)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this when you need to reset the TF graph.\n",
    "# tf.reset_default_graph()\n",
    "\"\"\"\n",
    "Transformer_classification: originally it perform sequence to sequence solely on attention mechanism. do it fast and better. now we use it to do text classification.\n",
    "for more detail, check paper: \"Attention Is All You Need\"\n",
    "1. position embedding for encoder input and decoder input\n",
    "2. encoder with multi-head attention, position-wise feed forward\n",
    "3. decoder with multi-head attention for decoder input,position-wise feed forward, mulit-head attention between encoder and decoder.\n",
    "encoder:\n",
    "6 layers.each layers has two sub-layers.\n",
    "the first is multi-head self-attention mechanism;\n",
    "the second is position-wise fully connected feed-forward network.\n",
    "for each sublayer. use LayerNorm(x+Sublayer(x)). all dimension=512.\n",
    "Decoder:\n",
    "1. The decoder is composed of a stack of N= 6 identical layers.\n",
    "2. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
    "attention over the output of the encoder stack.\n",
    "3. Similar to the encoder, we employ residual connections\n",
    "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
    "sub-layer in the decoder stack to prevent positions from attending to subsequent positions.  This\n",
    "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
    "predictions for position i can depend only on the known outputs at positions less than i.\n",
    "\"\"\"\n",
    "epochs = 100 # was 15000\n",
    "checkepoch = 10# was 1500\n",
    "\n",
    "class Transformer(BaseClass):\n",
    "    def __init__(self, num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length,\n",
    "                 vocab_size, embed_size,d_model,d_k,d_v,h,num_layer,is_training,\n",
    "                 initializer=tf.random_normal_initializer(stddev=0.1),clip_gradients=5.0,l2_lambda=0.0001,use_residual_conn=False):\n",
    "        \"\"\"init all hyperparameter here\"\"\"\n",
    "        super(Transformer, self).__init__(d_model, d_k, d_v, sequence_length, h, batch_size, num_layer=num_layer) #init some fields by using parent class.\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = d_model\n",
    "        self.learning_rate = tf.Variable(learning_rate, trainable=False, name=\"learning_rate\")\n",
    "        self.learning_rate_decay_half_op = tf.assign(self.learning_rate, self.learning_rate * 0.5)\n",
    "        self.initializer = initializer\n",
    "        self.clip_gradients=clip_gradients\n",
    "        self.l2_lambda=l2_lambda\n",
    "\n",
    "        self.is_training=is_training #self.is_training=tf.placeholder(tf.bool,name=\"is_training\") #tf.bool #is_training\n",
    "        self.input_x = tf.placeholder(tf.int32, [self.batch_size, self.sequence_length], name=\"input_x\")                 #x  batch_size\n",
    "        self.input_y_label = tf.placeholder(tf.int32, [self.batch_size], name=\"input_y_label\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        self.global_step = tf.Variable(0, trainable=False, name=\"Global_Step\")\n",
    "        self.epoch_step = tf.Variable(0, trainable=False, name=\"Epoch_Step\")\n",
    "        self.epoch_increment = tf.assign(self.epoch_step, tf.add(self.epoch_step, tf.constant(1)))\n",
    "        self.decay_steps, self.decay_rate = decay_steps, decay_rate\n",
    "        self.use_residual_conn=use_residual_conn\n",
    "\n",
    "        self.instantiate_weights()\n",
    "        self.logits = self.inference() #logits shape:[batch_size,self.num_classes]\n",
    "\n",
    "        self.predictions = tf.argmax(self.logits, axis=1, name=\"predictions\")\n",
    "        correct_prediction = tf.equal(tf.cast(self.predictions, tf.int32),self.input_y_label)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"Accuracy\")  # shape=()\n",
    "        if self.is_training is False:# if it is not training, then no need to calculate loss and back-propagation.\n",
    "            return\n",
    "        self.loss_val = self.loss()\n",
    "        self.train_op = self.train()\n",
    "\n",
    "    def inference(self):\n",
    "        \"\"\" building blocks:\n",
    "        encoder:6 layers.each layers has two   sub-layers. the first is multi-head self-attention mechanism; the second is position-wise fully connected feed-forward network.\n",
    "               for each sublayer. use LayerNorm(x+Sublayer(x)). all dimension=512.\n",
    "        decoder:6 layers.each layers has three sub-layers. the second layer is performs multi-head attention over the ouput of the encoder stack.\n",
    "               for each sublayer. use LayerNorm(x+Sublayer(x)).\n",
    "        \"\"\"\n",
    "        # 1.embedding for encoder input & decoder input\n",
    "        # 1.1 position embedding for encoder input\n",
    "        input_x_embeded = tf.nn.embedding_lookup(self.Embedding,self.input_x)  #[None,sequence_length, embed_size]\n",
    "        input_x_embeded=tf.multiply(input_x_embeded,tf.sqrt(tf.cast(self.d_model,dtype=tf.float32)))\n",
    "        input_mask=tf.get_variable(\"input_mask\",[self.sequence_length,1],initializer=self.initializer)\n",
    "        input_x_embeded=tf.add(input_x_embeded,input_mask) #[None,sequence_length,embed_size].position embedding.\n",
    "\n",
    "        # 2. encoder\n",
    "        encoder_class=Encoder(self.d_model,self.d_k,self.d_v,self.sequence_length,self.h,self.batch_size,self.num_layer,input_x_embeded,input_x_embeded,dropout_keep_prob=self.dropout_keep_prob,use_residual_conn=self.use_residual_conn)\n",
    "        Q_encoded,K_encoded = encoder_class.encoder_fn() #K_v_encoder\n",
    "\n",
    "        Q_encoded=tf.reshape(Q_encoded,shape=(self.batch_size,-1)) #[batch_size,sequence_length*d_model]\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            logits = tf.matmul(Q_encoded, self.W_projection) + self.b_projection #logits shape:[batch_size*decoder_sent_length,self.num_classes]\n",
    "        print(\"logits:\",logits)\n",
    "        return logits\n",
    "\n",
    "    def loss(self, l2_lambda=0.0001):  # 0.001\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            # input: `logits`:[batch_size, num_classes], and `labels`:[batch_size]\n",
    "            # output: A 1-D `Tensor` of length `batch_size` of the same type as `logits` with the softmax cross entropy loss.\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.input_y_label,logits=self.logits);  # sigmoid_cross_entropy_with_logits.#losses=tf.nn.softmax_cross_entropy_with_logits(labels=self.input_y,logits=self.logits)\n",
    "            # print(\"1.sparse_softmax_cross_entropy_with_logits.losses:\",losses) # shape=(?,)\n",
    "            loss = tf.reduce_mean(losses)  # print(\"2.loss.loss:\", loss) #shape=()\n",
    "            l2_losses = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables() if ('bias' not in v.name ) and ('alpha' not in v.name)]) * l2_lambda\n",
    "            loss = loss + l2_losses\n",
    "        return loss\n",
    "\n",
    "    #def loss_seq2seq(self):\n",
    "    #    with tf.variable_scope(\"loss\"):\n",
    "    #        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.input_y_label, logits=self.logits);#losses:[batch_size,self.decoder_sent_length]\n",
    "    #        loss_batch=tf.reduce_sum(losses,axis=1)/self.decoder_sent_length #loss_batch:[batch_size]\n",
    "    #        loss=tf.reduce_mean(loss_batch)\n",
    "    #        l2_losses = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables() if 'bias' not in v.name]) * self.l2_lambda\n",
    "    #        loss = loss + l2_losses\n",
    "    #        return loss\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"based on the loss, use SGD to update parameter\"\"\"\n",
    "        learning_rate = tf.train.exponential_decay(self.learning_rate, self.global_step, self.decay_steps,self.decay_rate, staircase=True)\n",
    "        self.learning_rate_=learning_rate\n",
    "        #noise_std_dev = tf.constant(0.3) / (tf.sqrt(tf.cast(tf.constant(1) + self.global_step, tf.float32))) #gradient_noise_scale=noise_std_dev\n",
    "        train_op = tf.contrib.layers.optimize_loss(self.loss_val, global_step=self.global_step,\n",
    "                                                   learning_rate=learning_rate, optimizer=\"Adam\",clip_gradients=self.clip_gradients)\n",
    "        return train_op\n",
    "\n",
    "    def instantiate_weights(self):\n",
    "        \"\"\"define all weights here\"\"\"\n",
    "        with tf.variable_scope(\"embedding_projection\"):  # embedding matrix\n",
    "            self.Embedding = tf.get_variable(\"Embedding\", shape=[self.vocab_size, self.embed_size],initializer=self.initializer)  # [vocab_size,embed_size] tf.random_uniform([self.vocab_size, self.embed_size],-1.0,1.0)\n",
    "            self.Embedding_label = tf.get_variable(\"Embedding_label\", shape=[self.num_classes, self.embed_size],dtype=tf.float32) #,initializer=self.initializer\n",
    "            self.W_projection = tf.get_variable(\"W_projection\", shape=[self.sequence_length*self.d_model, self.num_classes],initializer=self.initializer)  # [embed_size,label_size]\n",
    "            self.b_projection = tf.get_variable(\"b_projection\", shape=[self.num_classes])\n",
    "\n",
    "    def get_mask(self,sequence_length):\n",
    "        lower_triangle = tf.matrix_band_part(tf.ones([sequence_length, sequence_length]), -1, 0)\n",
    "        result = -1e9 * (1.0 - lower_triangle)\n",
    "        print(\"get_mask==>result:\", result)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "# test started: learn to predict the bigger number in two numbers from specific location of array.\n",
    "def test_training():\n",
    "\n",
    "    # below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.\n",
    "    num_classes = 9+2 #additional two classes:one is for _GO, another is for _END\n",
    "    learning_rate = 0.0001 #/10.0\n",
    "    batch_size = 1 # was 1\n",
    "    decay_steps = 1000\n",
    "    decay_rate = 0.9\n",
    "    sequence_length = 6#5 TODO\n",
    "    vocab_size = 300\n",
    "    is_training = True #True\n",
    "    dropout_keep_prob = 0.9  # 0.5 #num_sentences\n",
    "    #decoder_sent_length=6\n",
    "    l2_lambda=0.0001#0.0001\n",
    "    d_model=512 #512\n",
    "    d_k=64\n",
    "    d_v=64\n",
    "    h=8\n",
    "    num_layer=1\n",
    "    embed_size = d_model\n",
    "\n",
    "    model = Transformer(num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length,\n",
    "                        vocab_size, embed_size,d_model,d_k,d_v,h,num_layer,is_training,l2_lambda=l2_lambda)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    acc_arr = []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # writer.add_graph(sess.graph)\n",
    "        writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "        \n",
    "        ckpt_dir = 'checkpoint_transformer/sequence_reverse/'\n",
    "        \n",
    "        if not os.path.exists(ckpt_dir):\n",
    "            os.makedirs(ckpt_dir)\n",
    "        \n",
    "        if os.path.exists(ckpt_dir+\"checkpoint\"):\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(ckpt_dir))\n",
    "            \n",
    "        for i in range(epochs):\n",
    "            label_list= get_unique_labels()\n",
    "            input_x = np.array([label_list+[9]],dtype=np.int32)\n",
    "            label_list_original=copy.deepcopy(label_list)\n",
    "            label_list.reverse()\n",
    "            input_y_label=np.array([np.max([label_list[0],label_list[1]])],dtype=np.int32)\n",
    "\n",
    "            loss, acc, predict, W_projection_value, _ = sess.run([model.loss_val, model.accuracy, model.predictions, model.W_projection, model.train_op],\n",
    "                                                     feed_dict={model.input_x:input_x, model.input_y_label: input_y_label,\n",
    "                                                                model.dropout_keep_prob: dropout_keep_prob}) #model.dropout_keep_prob: dropout_keep_prob\n",
    "            print(i,\"loss:\", loss, \"acc:\", acc, \"label_list_original as input x:\",label_list_original,\";input_y_label:\", input_y_label, \"prediction:\", predict)\n",
    "            acc_arr.append(acc)\n",
    "            if i%checkepoch==0:\n",
    "                save_path = ckpt_dir + \"model.ckpt\"\n",
    "                saver.save(sess, save_path, global_step=i)\n",
    "\n",
    "#test_training()\n",
    "#test_predict()\n",
    "#test_training_batch()\n",
    "#test_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    # below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.\n",
    "    num_classes = 9+2 #additional two classes:one is for _GO, another is for _END\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 1\n",
    "    decay_steps = 1000\n",
    "    decay_rate = 0.9\n",
    "    sequence_length = 6 #5\n",
    "    vocab_size = 300\n",
    "    is_training = False #True\n",
    "    dropout_keep_prob = 1  # 0.5 #num_sentences\n",
    "    l2_lambda=0.0001\n",
    "    d_model=512 #512\n",
    "    d_k=64\n",
    "    d_v=64\n",
    "    h=8\n",
    "    num_layer=1#6\n",
    "    embed_size = d_model\n",
    "    model = Transformer(num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length,\n",
    "                                    vocab_size, embed_size,d_model,d_k,d_v,h,num_layer,is_training,l2_lambda=l2_lambda)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt_dir = 'checkpoint_transformer/sequence_reverse/'\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(ckpt_dir))\n",
    "        print(\"=================restored.\")\n",
    "        for i in range(checkepoch):\n",
    "            label_list=get_unique_labels()\n",
    "            input_x = np.array([label_list+[9]],dtype=np.int32)\n",
    "            label_list_original=copy.deepcopy(label_list)\n",
    "            label_list.reverse()\n",
    "            input_y_label=np.array([np.max([label_list[0],label_list[1]])],dtype=np.int32)\n",
    "\n",
    "            predict, W_projection_value = sess.run([ model.predictions, model.W_projection], #model.loss_val,--->loss, model.train_op\n",
    "                                feed_dict={model.input_x:input_x,\n",
    "                                           model.dropout_keep_prob: dropout_keep_prob})\n",
    "            print(i, \"label_list_original as input x:\",label_list_original, \"prediction:\", predict,\";label:\",input_y_label) #\"acc:\", acc, \"loss:\", loss \";input_y_label:\", input_y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_fn.started.\n",
      "MultiHeadAttention.self.dropout_rate: Tensor(\"base_mode_sub_layer_multi_head_attention_encoder0/sub:0\", dtype=float32)\n",
      "scaled_dot_product_attention_batch.===============================================================>mask is not none? False\n",
      "dot_product:====================================================================================> Tensor(\"base_mode_sub_layer_multi_head_attention_encoder0/MatMul_1:0\", shape=(1, 8, 6, 64), dtype=float32)\n",
      "self.sequence_length: 6\n",
      "@@@========================>layer_input: Tensor(\"Add_1:0\", shape=(1, 6, 512), dtype=float32) ;layer_output: Tensor(\"base_mode_sub_layer_multi_head_attention_encoder0/dense_3/BiasAdd:0\", shape=(1, 6, 512), dtype=float32)\n",
      "LayerNormResidualConnection.use_residual_conn: False\n",
      "layer_normalization:==================>variable_scope: layer_normalization0encoder_multi_head_attention\n",
      "WARNING:tensorflow:From /mnt/data/OProjects/DeepLearning/HPC2N/TFnDeepLearning/codes/pythonlibs/embeddings/transformers/a2_layer_norm_residual_conn.py:39: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "output_conv1: Tensor(\"sub_layer_postion_wise_feed_forwardencoder0/transpose:0\", shape=(1, 6, 2048, 1), dtype=float32)\n",
      "@@@========================>layer_input: Tensor(\"layer_normalization0encoder_multi_head_attention/add_1:0\", shape=(1, 6, 512), dtype=float32) ;layer_output: Tensor(\"sub_layer_postion_wise_feed_forwardencoder0/Squeeze:0\", shape=(6, 512), dtype=float32)\n",
      "LayerNormResidualConnection.use_residual_conn: True\n",
      "layer_normalization:==================>variable_scope: layer_normalization0encoder_postion_wise_ff\n",
      "encoder_fn. 0 .Q: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32) ;K_s: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32)\n",
      "encoder_fn.ended.Q: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32) ;K_s: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32) ;time spent: 0.21437788009643555\n",
      "logits: Tensor(\"output/add:0\", shape=(1, 11), dtype=float32)\n",
      "0 loss: 9.355153 acc: 0.0 label_list_original as input x: [6, 3, 2, 4, 5] ;input_y_label: [5] prediction: [7]\n",
      "1 loss: 12.863681 acc: 0.0 label_list_original as input x: [6, 4, 3, 2, 5] ;input_y_label: [5] prediction: [2]\n",
      "2 loss: 31.670769 acc: 0.0 label_list_original as input x: [5, 2, 6, 4, 3] ;input_y_label: [4] prediction: [2]\n",
      "3 loss: 20.271753 acc: 0.0 label_list_original as input x: [4, 5, 3, 2, 6] ;input_y_label: [6] prediction: [2]\n",
      "4 loss: 9.68086 acc: 0.0 label_list_original as input x: [4, 6, 2, 3, 5] ;input_y_label: [5] prediction: [2]\n",
      "5 loss: 23.723845 acc: 0.0 label_list_original as input x: [2, 5, 6, 4, 3] ;input_y_label: [4] prediction: [2]\n",
      "6 loss: 33.21771 acc: 0.0 label_list_original as input x: [6, 3, 5, 2, 4] ;input_y_label: [4] prediction: [7]\n",
      "7 loss: 19.521526 acc: 0.0 label_list_original as input x: [2, 5, 3, 4, 6] ;input_y_label: [6] prediction: [7]\n",
      "8 loss: 2.4738784 acc: 0.0 label_list_original as input x: [2, 3, 6, 4, 5] ;input_y_label: [5] prediction: [7]\n",
      "9 loss: 25.602257 acc: 0.0 label_list_original as input x: [5, 4, 3, 2, 6] ;input_y_label: [6] prediction: [2]\n",
      "10 loss: 17.54075 acc: 0.0 label_list_original as input x: [3, 4, 2, 6, 5] ;input_y_label: [6] prediction: [2]\n",
      "11 loss: 14.693481 acc: 0.0 label_list_original as input x: [5, 3, 2, 4, 6] ;input_y_label: [6] prediction: [2]\n",
      "12 loss: 13.650366 acc: 0.0 label_list_original as input x: [6, 4, 2, 5, 3] ;input_y_label: [5] prediction: [8]\n",
      "13 loss: 6.253449 acc: 0.0 label_list_original as input x: [4, 6, 3, 5, 2] ;input_y_label: [5] prediction: [3]\n",
      "14 loss: 20.64759 acc: 0.0 label_list_original as input x: [5, 6, 3, 4, 2] ;input_y_label: [4] prediction: [5]\n",
      "15 loss: 13.985677 acc: 0.0 label_list_original as input x: [2, 4, 3, 5, 6] ;input_y_label: [6] prediction: [3]\n",
      "16 loss: 29.136204 acc: 0.0 label_list_original as input x: [3, 6, 5, 2, 4] ;input_y_label: [4] prediction: [2]\n",
      "17 loss: 9.470654 acc: 0.0 label_list_original as input x: [3, 5, 2, 6, 4] ;input_y_label: [6] prediction: [7]\n",
      "18 loss: 15.463593 acc: 0.0 label_list_original as input x: [2, 4, 5, 3, 6] ;input_y_label: [6] prediction: [7]\n",
      "19 loss: 1.9023042 acc: 1.0 label_list_original as input x: [6, 3, 2, 4, 5] ;input_y_label: [5] prediction: [5]\n",
      "20 loss: 2.2751198 acc: 1.0 label_list_original as input x: [4, 3, 6, 2, 5] ;input_y_label: [5] prediction: [5]\n",
      "21 loss: 1.6081088 acc: 1.0 label_list_original as input x: [4, 5, 6, 3, 2] ;input_y_label: [3] prediction: [3]\n",
      "22 loss: 10.934624 acc: 0.0 label_list_original as input x: [6, 3, 2, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "23 loss: 10.369431 acc: 0.0 label_list_original as input x: [3, 2, 4, 5, 6] ;input_y_label: [6] prediction: [7]\n",
      "24 loss: 14.830076 acc: 0.0 label_list_original as input x: [3, 2, 6, 5, 4] ;input_y_label: [5] prediction: [7]\n",
      "25 loss: 18.787968 acc: 0.0 label_list_original as input x: [3, 4, 5, 2, 6] ;input_y_label: [6] prediction: [2]\n",
      "26 loss: 1.920779 acc: 1.0 label_list_original as input x: [2, 6, 4, 3, 5] ;input_y_label: [5] prediction: [5]\n",
      "27 loss: 1.6549364 acc: 1.0 label_list_original as input x: [2, 3, 4, 5, 6] ;input_y_label: [6] prediction: [6]\n",
      "28 loss: 14.145273 acc: 0.0 label_list_original as input x: [5, 2, 3, 4, 6] ;input_y_label: [6] prediction: [5]\n",
      "29 loss: 9.367348 acc: 0.0 label_list_original as input x: [5, 4, 2, 3, 6] ;input_y_label: [6] prediction: [2]\n",
      "30 loss: 1.5051993 acc: 1.0 label_list_original as input x: [2, 6, 4, 5, 3] ;input_y_label: [5] prediction: [5]\n",
      "31 loss: 9.785585 acc: 0.0 label_list_original as input x: [3, 4, 2, 5, 6] ;input_y_label: [6] prediction: [8]\n",
      "32 loss: 7.9703197 acc: 0.0 label_list_original as input x: [5, 2, 4, 6, 3] ;input_y_label: [6] prediction: [1]\n",
      "33 loss: 4.714756 acc: 0.0 label_list_original as input x: [2, 4, 6, 3, 5] ;input_y_label: [5] prediction: [8]\n",
      "34 loss: 4.715047 acc: 0.0 label_list_original as input x: [6, 4, 2, 3, 5] ;input_y_label: [5] prediction: [8]\n",
      "35 loss: 7.3869667 acc: 0.0 label_list_original as input x: [3, 4, 2, 6, 5] ;input_y_label: [6] prediction: [2]\n",
      "36 loss: 16.176386 acc: 0.0 label_list_original as input x: [2, 6, 5, 3, 4] ;input_y_label: [4] prediction: [7]\n",
      "37 loss: 6.5503616 acc: 0.0 label_list_original as input x: [3, 4, 2, 6, 5] ;input_y_label: [6] prediction: [2]\n",
      "38 loss: 2.26825 acc: 1.0 label_list_original as input x: [3, 5, 4, 2, 6] ;input_y_label: [6] prediction: [6]\n",
      "39 loss: 6.0977464 acc: 0.0 label_list_original as input x: [2, 4, 3, 5, 6] ;input_y_label: [6] prediction: [3]\n",
      "40 loss: 20.56834 acc: 0.0 label_list_original as input x: [5, 6, 3, 4, 2] ;input_y_label: [4] prediction: [5]\n",
      "41 loss: 2.3624287 acc: 1.0 label_list_original as input x: [2, 4, 6, 3, 5] ;input_y_label: [5] prediction: [5]\n",
      "42 loss: 17.391861 acc: 0.0 label_list_original as input x: [3, 5, 6, 4, 2] ;input_y_label: [4] prediction: [5]\n",
      "43 loss: 3.8622162 acc: 0.0 label_list_original as input x: [6, 4, 2, 5, 3] ;input_y_label: [5] prediction: [8]\n",
      "44 loss: 6.1075783 acc: 0.0 label_list_original as input x: [3, 5, 2, 4, 6] ;input_y_label: [6] prediction: [2]\n",
      "45 loss: 5.6434727 acc: 0.0 label_list_original as input x: [2, 3, 6, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "46 loss: 1.4784323 acc: 1.0 label_list_original as input x: [4, 6, 2, 3, 5] ;input_y_label: [5] prediction: [5]\n",
      "47 loss: 1.4717449 acc: 1.0 label_list_original as input x: [3, 6, 2, 4, 5] ;input_y_label: [5] prediction: [5]\n",
      "48 loss: 1.6529334 acc: 1.0 label_list_original as input x: [3, 2, 4, 5, 6] ;input_y_label: [6] prediction: [6]\n",
      "49 loss: 6.948635 acc: 0.0 label_list_original as input x: [4, 3, 6, 5, 2] ;input_y_label: [5] prediction: [3]\n",
      "50 loss: 1.5509557 acc: 1.0 label_list_original as input x: [4, 3, 6, 2, 5] ;input_y_label: [5] prediction: [5]\n",
      "51 loss: 3.8925076 acc: 0.0 label_list_original as input x: [4, 6, 5, 3, 2] ;input_y_label: [3] prediction: [5]\n",
      "52 loss: 1.5597279 acc: 1.0 label_list_original as input x: [4, 2, 3, 6, 5] ;input_y_label: [6] prediction: [6]\n",
      "53 loss: 3.393159 acc: 0.0 label_list_original as input x: [4, 2, 6, 5, 3] ;input_y_label: [5] prediction: [3]\n",
      "54 loss: 1.8030424 acc: 1.0 label_list_original as input x: [4, 5, 3, 2, 6] ;input_y_label: [6] prediction: [6]\n",
      "55 loss: 6.6249156 acc: 0.0 label_list_original as input x: [4, 5, 6, 2, 3] ;input_y_label: [3] prediction: [5]\n",
      "56 loss: 1.489322 acc: 1.0 label_list_original as input x: [2, 3, 5, 6, 4] ;input_y_label: [6] prediction: [6]\n",
      "57 loss: 18.319416 acc: 0.0 label_list_original as input x: [5, 6, 2, 3, 4] ;input_y_label: [4] prediction: [5]\n",
      "58 loss: 18.08415 acc: 0.0 label_list_original as input x: [5, 6, 2, 3, 4] ;input_y_label: [4] prediction: [5]\n",
      "59 loss: 1.4625664 acc: 1.0 label_list_original as input x: [3, 4, 6, 2, 5] ;input_y_label: [5] prediction: [5]\n",
      "60 loss: 1.4571991 acc: 1.0 label_list_original as input x: [2, 3, 5, 6, 4] ;input_y_label: [6] prediction: [6]\n",
      "61 loss: 1.448146 acc: 1.0 label_list_original as input x: [4, 2, 3, 5, 6] ;input_y_label: [6] prediction: [6]\n",
      "62 loss: 30.018349 acc: 0.0 label_list_original as input x: [5, 6, 2, 4, 3] ;input_y_label: [4] prediction: [5]\n",
      "63 loss: 1.440246 acc: 1.0 label_list_original as input x: [4, 2, 3, 5, 6] ;input_y_label: [6] prediction: [6]\n",
      "64 loss: 5.395973 acc: 0.0 label_list_original as input x: [2, 3, 6, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "65 loss: 1.6356138 acc: 1.0 label_list_original as input x: [4, 2, 5, 6, 3] ;input_y_label: [6] prediction: [6]\n",
      "66 loss: 10.117658 acc: 0.0 label_list_original as input x: [6, 2, 4, 5, 3] ;input_y_label: [5] prediction: [6]\n",
      "67 loss: 1.4611481 acc: 1.0 label_list_original as input x: [6, 2, 3, 4, 5] ;input_y_label: [5] prediction: [5]\n",
      "68 loss: 17.944681 acc: 0.0 label_list_original as input x: [5, 2, 6, 3, 4] ;input_y_label: [4] prediction: [6]\n",
      "69 loss: 9.450896 acc: 0.0 label_list_original as input x: [6, 4, 5, 2, 3] ;input_y_label: [3] prediction: [5]\n",
      "70 loss: 14.514908 acc: 0.0 label_list_original as input x: [5, 6, 2, 3, 4] ;input_y_label: [4] prediction: [5]\n",
      "71 loss: 4.850239 acc: 0.0 label_list_original as input x: [2, 3, 6, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "72 loss: 6.310796 acc: 0.0 label_list_original as input x: [5, 4, 2, 6, 3] ;input_y_label: [6] prediction: [5]\n",
      "73 loss: 13.525149 acc: 0.0 label_list_original as input x: [3, 5, 6, 4, 2] ;input_y_label: [4] prediction: [5]\n",
      "74 loss: 1.4108182 acc: 1.0 label_list_original as input x: [2, 6, 3, 4, 5] ;input_y_label: [5] prediction: [5]\n",
      "75 loss: 26.703388 acc: 0.0 label_list_original as input x: [6, 5, 2, 3, 4] ;input_y_label: [4] prediction: [6]\n",
      "76 loss: 11.206307 acc: 0.0 label_list_original as input x: [6, 3, 2, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "77 loss: 18.392382 acc: 0.0 label_list_original as input x: [6, 3, 5, 4, 2] ;input_y_label: [4] prediction: [5]\n",
      "78 loss: 18.582232 acc: 0.0 label_list_original as input x: [5, 6, 4, 2, 3] ;input_y_label: [3] prediction: [5]\n",
      "79 loss: 11.411314 acc: 0.0 label_list_original as input x: [2, 5, 6, 3, 4] ;input_y_label: [4] prediction: [6]\n",
      "80 loss: 1.4162823 acc: 1.0 label_list_original as input x: [6, 2, 3, 4, 5] ;input_y_label: [5] prediction: [5]\n",
      "81 loss: 4.2176113 acc: 0.0 label_list_original as input x: [5, 4, 3, 6, 2] ;input_y_label: [6] prediction: [4]\n",
      "82 loss: 6.09862 acc: 0.0 label_list_original as input x: [5, 4, 3, 2, 6] ;input_y_label: [6] prediction: [5]\n",
      "83 loss: 6.708599 acc: 0.0 label_list_original as input x: [3, 2, 6, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "84 loss: 1.487946 acc: 1.0 label_list_original as input x: [4, 3, 5, 6, 2] ;input_y_label: [6] prediction: [6]\n",
      "85 loss: 3.9138908 acc: 0.0 label_list_original as input x: [4, 5, 6, 2, 3] ;input_y_label: [3] prediction: [5]\n",
      "86 loss: 9.719755 acc: 0.0 label_list_original as input x: [6, 2, 3, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "87 loss: 9.522191 acc: 0.0 label_list_original as input x: [6, 2, 3, 5, 4] ;input_y_label: [5] prediction: [6]\n",
      "88 loss: 1.4628919 acc: 1.0 label_list_original as input x: [3, 6, 2, 5, 4] ;input_y_label: [5] prediction: [5]\n",
      "89 loss: 1.3921179 acc: 1.0 label_list_original as input x: [3, 2, 4, 5, 6] ;input_y_label: [6] prediction: [6]\n",
      "90 loss: 1.3907119 acc: 1.0 label_list_original as input x: [3, 2, 4, 5, 6] ;input_y_label: [6] prediction: [6]\n",
      "91 loss: 13.349418 acc: 0.0 label_list_original as input x: [3, 6, 5, 2, 4] ;input_y_label: [4] prediction: [5]\n",
      "92 loss: 22.673708 acc: 0.0 label_list_original as input x: [5, 6, 2, 4, 3] ;input_y_label: [4] prediction: [5]\n",
      "93 loss: 1.4904389 acc: 1.0 label_list_original as input x: [4, 2, 5, 3, 6] ;input_y_label: [6] prediction: [6]\n",
      "94 loss: 1.38024 acc: 1.0 label_list_original as input x: [4, 6, 3, 2, 5] ;input_y_label: [5] prediction: [5]\n",
      "95 loss: 13.525934 acc: 0.0 label_list_original as input x: [3, 6, 5, 4, 2] ;input_y_label: [4] prediction: [5]\n",
      "96 loss: 3.5434747 acc: 0.0 label_list_original as input x: [2, 4, 3, 6, 5] ;input_y_label: [6] prediction: [5]\n",
      "97 loss: 1.3735675 acc: 1.0 label_list_original as input x: [2, 3, 6, 4, 5] ;input_y_label: [5] prediction: [5]\n",
      "98 loss: 1.4382597 acc: 1.0 label_list_original as input x: [6, 4, 3, 2, 5] ;input_y_label: [5] prediction: [5]\n",
      "99 loss: 8.52429 acc: 0.0 label_list_original as input x: [3, 5, 6, 4, 2] ;input_y_label: [4] prediction: [5]\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "test_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.029598204821446816&quot;).pbtxt = 'node {\\n  name: &quot;Embedding_E/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\350\\\\003\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;Embedding_E/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Embedding_E/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;Embedding_E/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Embedding_E/Initializer/random_normal/mul&quot;\\n  input: &quot;Embedding_E/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1000\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Embedding_E&quot;\\n  input: &quot;Embedding_E/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Embedding_E/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Embedding_E&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_x&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 128\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup&quot;\\n  op: &quot;GatherV2&quot;\\n  input: &quot;Embedding_E/read&quot;\\n  input: &quot;input_x&quot;\\n  input: &quot;embedding_lookup/axis&quot;\\n  attr {\\n    key: &quot;Taxis&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;embedding_lookup&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ones&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;ones/shape_as_tensor&quot;\\n  input: &quot;ones/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatrixBandPart/num_lower&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatrixBandPart/num_upper&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatrixBandPart&quot;\\n  op: &quot;MatrixBandPart&quot;\\n  input: &quot;ones&quot;\\n  input: &quot;MatrixBandPart/num_lower&quot;\\n  input: &quot;MatrixBandPart/num_upper&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindex&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;sub/x&quot;\\n  input: &quot;MatrixBandPart&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1000000000.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;learning_rate/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.999999747378752e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;learning_rate&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;learning_rate/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;learning_rate/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@learning_rate&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;learning_rate/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;learning_rate&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@learning_rate&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;learning_rate/read&quot;\\n  input: &quot;mul_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@learning_rate&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_x_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 6\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_y_label&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout_keep_prob&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Global_Step/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Global_Step&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Global_Step/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Global_Step&quot;\\n  input: &quot;Global_Step/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Global_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Global_Step/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Global_Step&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Global_Step&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Epoch_Step/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Epoch_Step&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Epoch_Step/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Epoch_Step&quot;\\n  input: &quot;Epoch_Step/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Epoch_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Epoch_Step/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;Epoch_Step&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Epoch_Step&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Epoch_Step/read&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Epoch_Step&quot;\\n  input: &quot;Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Epoch_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;embedding_projection/Embedding/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/Embedding/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;embedding_projection/Embedding/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;embedding_projection/Embedding/Initializer/random_normal/mul&quot;\\n  input: &quot;embedding_projection/Embedding/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/Embedding&quot;\\n  input: &quot;embedding_projection/Embedding/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;embedding_projection/Embedding&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\013\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.1071087047457695\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.1071087047457695\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/max&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/mul&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 11\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/Embedding_label&quot;\\n  input: &quot;embedding_projection/Embedding_label/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/Embedding_label/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;embedding_projection/Embedding_label&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\014\\\\000\\\\000\\\\013\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;embedding_projection/W_projection/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/W_projection/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;embedding_projection/W_projection/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;embedding_projection/W_projection/Initializer/random_normal/mul&quot;\\n  input: &quot;embedding_projection/W_projection/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3072\\n        }\\n        dim {\\n          size: 11\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/W_projection&quot;\\n  input: &quot;embedding_projection/W_projection/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/W_projection/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;embedding_projection/W_projection&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 11\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.5222329497337341\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5222329497337341\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/max&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/mul&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 11\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/b_projection&quot;\\n  input: &quot;embedding_projection/b_projection/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_projection/b_projection/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;embedding_projection/b_projection&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup_1&quot;\\n  op: &quot;GatherV2&quot;\\n  input: &quot;embedding_projection/Embedding/read&quot;\\n  input: &quot;input_x_1&quot;\\n  input: &quot;embedding_lookup_1/axis&quot;\\n  attr {\\n    key: &quot;Taxis&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tparams&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;embedding_lookup_1/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;embedding_lookup_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Cast/x&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_lookup_1/Identity&quot;\\n  input: &quot;Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;input_mask/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;input_mask/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;input_mask/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;input_mask/Initializer/random_normal/mul&quot;\\n  input: &quot;input_mask/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 6\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;input_mask&quot;\\n  input: &quot;input_mask/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_mask/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;input_mask&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;Mul_2&quot;\\n  input: &quot;input_mask/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 6\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub/x&quot;\\n  input: &quot;dropout_keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;Add_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/read&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/transpose_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/Tensordot&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;Add_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/read&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/transpose_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/Tensordot&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/read&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/read&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/transpose_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/Tensordot&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 8\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split/split_dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split/split_dim&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:2&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:3&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:4&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:5&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:6&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split:7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 8\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1/split_dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1/split_dim&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/stack_1&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:2&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:3&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:4&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:5&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:6&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_1:7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Const_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 8\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2/split_dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2&quot;\\n  op: &quot;Split&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2/split_dim&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;num_split&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/stack_2&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:2&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:3&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:4&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:5&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:6&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/split_2:7&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/MatMul&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/stack&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/stack_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Cast/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Cast/x&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/truediv/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/truediv/x&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub_1/x&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/max&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Softmax&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/div&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/MatMul_1&quot;\\n  op: &quot;BatchMatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dropout/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/stack_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_x&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;adj_y&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/MatMul_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0765465572476387\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose_1/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose_1&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/read&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose_1/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape_1/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/transpose_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape_1/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/MatMul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/Tensordot&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;sub_1/x&quot;\\n  input: &quot;dropout_keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Add_1&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Add_1&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/Mean_1/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Square&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean_1/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;Add_1&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.999999974752427e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean_1&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/sub_1&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_multi_head_attention/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/mul_1&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/add_1&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/mul&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 2048\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2048\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 2048\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/dilation_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/ExpandDims&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dilations&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/Conv2D&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/transpose/perm&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/transpose&quot;\\n  op: &quot;Transpose&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/Relu&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/transpose/perm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tperm&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/mean&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/stddev&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.10000000149011612\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/RandomStandardNormal&quot;\\n  op: &quot;RandomStandardNormal&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/RandomStandardNormal&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/stddev&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/mul&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal/mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 2048\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Initializer/random_normal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/dilation_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/transpose&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dilations&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/Conv2D&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_layer_postion_wise_feed_forwardencoder0/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_2/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;sub_2/x&quot;\\n  input: &quot;dropout_keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/Mean/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/add_1&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/add_1&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/Mean_1/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Square&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean_1/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/add_1&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.999999974752427e-07\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean_1&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/Rsqrt&quot;\\n  op: &quot;Rsqrt&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/sub_1&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Initializer/ones&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Initializer/ones&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_normalization0encoder_postion_wise_ff/add_1&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/mul_1&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\377\\\\377\\\\377\\\\377&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/add_1&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;embedding_projection/W_projection/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output/MatMul&quot;\\n  input: &quot;embedding_projection/b_projection/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;output/add&quot;\\n  input: &quot;predictions/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast_1&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;predictions&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;Cast_1&quot;\\n  input: &quot;input_y_label&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast_2&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;output/add&quot;\\n  input: &quot;input_y_label&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;Embedding_E/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_1&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;embedding_projection/Embedding/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_2&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;embedding_projection/Embedding_label/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_3&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;embedding_projection/W_projection/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_4&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;embedding_projection/b_projection/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_5&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;input_mask/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_6&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_7&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_8&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_9&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_10&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_11&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_12&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_13&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/L2Loss_14&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;loss/L2Loss&quot;\\n  input: &quot;loss/L2Loss_1&quot;\\n  input: &quot;loss/L2Loss_2&quot;\\n  input: &quot;loss/L2Loss_3&quot;\\n  input: &quot;loss/L2Loss_4&quot;\\n  input: &quot;loss/L2Loss_5&quot;\\n  input: &quot;loss/L2Loss_6&quot;\\n  input: &quot;loss/L2Loss_7&quot;\\n  input: &quot;loss/L2Loss_8&quot;\\n  input: &quot;loss/L2Loss_9&quot;\\n  input: &quot;loss/L2Loss_10&quot;\\n  input: &quot;loss/L2Loss_11&quot;\\n  input: &quot;loss/L2Loss_12&quot;\\n  input: &quot;loss/L2Loss_13&quot;\\n  input: &quot;loss/L2Loss_14&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 15\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.999999747378752e-05\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss/AddN&quot;\\n  input: &quot;loss/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/Mean&quot;\\n  input: &quot;loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1000\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;ExponentialDecay/Cast/x&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Cast_2&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Global_Step/read&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;ExponentialDecay/Cast_2&quot;\\n  input: &quot;ExponentialDecay/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;ExponentialDecay/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay/Pow&quot;\\n  op: &quot;Pow&quot;\\n  input: &quot;ExponentialDecay/Cast_1/x&quot;\\n  input: &quot;ExponentialDecay/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExponentialDecay&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;learning_rate/read&quot;\\n  input: &quot;ExponentialDecay/Pow&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/gradients/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/Fill&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Fill&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/Fill&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Fill&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/Fill&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/Mean_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/Mean_grad/Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;loss/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;loss/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/Mul_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/Mean_grad/truediv&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_8&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_9&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_10&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_11&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_12&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_13&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_14&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;^OptimizeLoss/gradients/loss/AddN_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\013\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 11\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/add_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Embedding_E/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_1_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/Embedding/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/Embedding_label/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/W_projection/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_4_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_projection/b_projection/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;input_mask/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/read&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/AddN_grad/tuple/control_dependency_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/tuple/control_dependency&quot;\\n  input: &quot;embedding_projection/W_projection/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/MatMul_grad/MatMul&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/output/MatMul_grad/MatMul&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/output/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/output/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/output/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/output/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_4_grad/mul&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/output/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/output/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/Reshape_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/sub_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Rsqrt_grad/RsqrtGrad&quot;\\n  op: &quot;RsqrtGrad&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Rsqrt&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean_1/reduction_indices&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/add&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/range/start&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Size&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/mod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 512.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/sub&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_1_grad/truediv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Square_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_3&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/Mean/reduction_indices&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/add&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/range/start&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Size&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/mod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_3&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 512.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_4&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_4&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_4&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 512\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Rsqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/sub_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_5&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Rsqrt_grad/RsqrtGrad&quot;\\n  op: &quot;RsqrtGrad&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Rsqrt&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Rsqrt_grad/RsqrtGrad&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean_1/reduction_indices&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/add&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/range/start&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Size&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/mod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 512.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/sub&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_1_grad/truediv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Square_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Neg&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_6&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/Mean/reduction_indices&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/add&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/range/start&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Size&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape_1&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/range&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/mod&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/DynamicStitch&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_6&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 512.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Tile&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_7&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/sub_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\006\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_7&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_7&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/Add_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/Add_1_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/Add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/Add_1_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Add_1_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/Add_1_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/Add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Shape&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/tuple/control_dependency&quot;\\n  input: &quot;Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;embedding_lookup_1/Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Mul_1&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Sum_1&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/gradients/Mul_2_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/Mul_2_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Reshape&quot;\\n  input: &quot;^OptimizeLoss/gradients/Mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/Mul_2_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Mul_2_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/Reshape_1&quot;\\n  input: &quot;^OptimizeLoss/gradients/Mul_2_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/Mul_2_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/AddN_8&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/Add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\000\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Shape&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 6\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Size&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ToInt32&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice/stack&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice/stack_1&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/strided_slice&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/Mul_2_grad/tuple/control_dependency&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;input_x_1&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/ExpandDims&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;OptimizeLoss/gradients/Shape_1&quot;\\n  input: &quot;OptimizeLoss/gradients/strided_slice/stack&quot;\\n  input: &quot;OptimizeLoss/gradients/strided_slice/stack_1&quot;\\n  input: &quot;OptimizeLoss/gradients/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;OptimizeLoss/gradients/range/start&quot;\\n  input: &quot;OptimizeLoss/gradients/strided_slice&quot;\\n  input: &quot;OptimizeLoss/gradients/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_1_grad/mul&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Reshape&quot;\\n  input: &quot;OptimizeLoss/gradients/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/gradients/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;OptimizeLoss/gradients/range&quot;\\n  input: &quot;OptimizeLoss/gradients/embedding_lookup_1_grad/Reshape_1&quot;\\n  input: &quot;OptimizeLoss/gradients/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_1&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_2&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_3&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_4&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_5&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_6&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_7&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_8&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_9&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_10&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_11&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_12&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_13&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_14&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_15&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/L2Loss_16&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_1&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_2&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_3&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_4&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_5&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_6&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_7&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_8&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_9&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_10&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_11&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_12&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_13&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_14&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_15&quot;\\n  input: &quot;OptimizeLoss/global_norm/L2Loss_16&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/global_norm/stack&quot;\\n  input: &quot;OptimizeLoss/global_norm/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/global_norm/Sum&quot;\\n  input: &quot;OptimizeLoss/global_norm/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/global_norm&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;OptimizeLoss/global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/gradient_norm/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;OptimizeLoss/global_norm/gradient_norm&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/gradient_norm&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;OptimizeLoss/global_norm/gradient_norm/tags&quot;\\n  input: &quot;OptimizeLoss/global_norm/global_norm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_1&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_2&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_3&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_4&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_5&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_6&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_7&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_8&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_9&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_10&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_11&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_12&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_13&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_14&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_15&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/L2Loss_16&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_1&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_2&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_3&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_4&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_5&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_6&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_7&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_8&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_9&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_10&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_11&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_12&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_13&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_14&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_15&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/L2Loss_16&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/stack&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/Sum&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_1/global_norm&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/VerifyFinite/CheckNumerics&quot;\\n  op: &quot;CheckNumerics&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/global_norm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/global_norm_1/global_norm&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Found Inf or NaN global norm.&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/VerifyFinite/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/global_norm_1/global_norm&quot;\\n  input: &quot;^OptimizeLoss/VerifyFinite/CheckNumerics&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/global_norm_1/global_norm&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/truediv/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/truediv/x&quot;\\n  input: &quot;OptimizeLoss/VerifyFinite/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/truediv_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 5.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/truediv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/Const&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/truediv_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/truediv&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/truediv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 5.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul/x&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/Minimum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/concat&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_2&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_4&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_1&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_3&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_5&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_4&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_6&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_8&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_5&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_7&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_6&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_8&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_7&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_9&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_9&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_10&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_11&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_11&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_13&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_12&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_5&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_15&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_13&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_16&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_14&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_17&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_15&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_19&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_16&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/AddN_2&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_21&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/mul_17&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/tuple/control_dependency_1&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_22&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/mul_17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/loss/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;OptimizeLoss/loss&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/loss&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;OptimizeLoss/loss/tags&quot;\\n  input: &quot;loss/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_1&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/concat&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_2&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_2_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_3&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_3_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_4&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/output/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_5&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_5_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_6&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_6_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_7&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_7_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_8&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_8_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_9&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_9_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_10&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_10_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_11&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_11_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_12&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_multi_head_attention/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_13&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_12_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_14&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_13_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_15&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_21&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/loss/L2Loss_14_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/L2Loss_16&quot;\\n  op: &quot;L2Loss&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_22&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@OptimizeLoss/gradients/layer_normalization0encoder_postion_wise_ff/add_1_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/stack&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_1&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_2&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_3&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_4&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_5&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_6&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_7&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_8&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_9&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_10&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_11&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_12&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_13&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_14&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_15&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/L2Loss_16&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 17\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/stack&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/Sum&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm_2/global_norm&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/clipped_gradient_norm/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;OptimizeLoss/global_norm/clipped_gradient_norm&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/global_norm/clipped_gradient_norm&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;OptimizeLoss/global_norm/clipped_gradient_norm/tags&quot;\\n  input: &quot;OptimizeLoss/global_norm_2/global_norm&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta1_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta1_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta1_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/beta1_power&quot;\\n  input: &quot;OptimizeLoss/beta1_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta1_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/beta1_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta2_power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta2_power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta2_power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/beta2_power&quot;\\n  input: &quot;OptimizeLoss/beta2_power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/beta2_power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/beta2_power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\350\\\\003\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1000\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\350\\\\003\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1000\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/Embedding_E/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\013\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 11\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\013\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 11\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\014\\\\000\\\\000\\\\013\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3072\\n        }\\n        dim {\\n          size: 11\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\014\\\\000\\\\000\\\\013\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3072\\n        }\\n        dim {\\n          size: 11\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 11\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 11\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 11\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 11\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 6\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 6\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/input_mask/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 6\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 6\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\002\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 2048\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 512\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 2048\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 2048\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\000\\\\010\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\000\\\\002\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Initializer/zeros/shape_as_tensor&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Initializer/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 2048\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 512\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 512\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_Embedding_E/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;Embedding_E&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Unique&quot;\\n  op: &quot;Unique&quot;\\n  input: &quot;OptimizeLoss/gradients/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_idx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Unique&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice/stack&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice/stack_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice/stack_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice&quot;\\n  op: &quot;StridedSlice&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Shape&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice/stack&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice/stack_1&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice/stack_2&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;begin_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;ellipsis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;end_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;new_axis_mask&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;shrink_axis_mask&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/UnsortedSegmentSum&quot;\\n  op: &quot;UnsortedSegmentSum&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_1&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Unique:1&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/strided_slice&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tnumsegments&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub/x&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_1/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_1/x&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_2/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_2/x&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/UnsortedSegmentSum&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_2&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam/read&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/ScatterAdd&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Unique&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_1&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/Assign&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_3&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/UnsortedSegmentSum&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/UnsortedSegmentSum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_3/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_3&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_3/x&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_4&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_3&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/sub_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_5&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1/read&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/ScatterAdd_1&quot;\\n  op: &quot;ScatterAdd&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Unique&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_4&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/Assign_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tindices&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Sqrt_1&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_6&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/truediv&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/ScatterAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/Sqrt_1&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/truediv_1&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/mul_6&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/AssignSub&quot;\\n  op: &quot;AssignSub&quot;\\n  input: &quot;embedding_projection/Embedding&quot;\\n  input: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/truediv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/AssignSub&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/ScatterAdd&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/ScatterAdd_1&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/Embedding_label/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;embedding_projection/Embedding_label&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/W_projection/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;embedding_projection/W_projection&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_embedding_projection/b_projection/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;embedding_projection/b_projection&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_input_mask/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;input_mask&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/V_s/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_scale/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_scale/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_21&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;ExponentialDecay&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;OptimizeLoss/train/epsilon&quot;\\n  input: &quot;OptimizeLoss/clip_by_global_norm/OptimizeLoss/clip_by_global_norm/_22&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/beta1_power/read&quot;\\n  input: &quot;OptimizeLoss/train/beta1&quot;\\n  input: &quot;^OptimizeLoss/train/update_Embedding_E/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/V_s/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/group_deps&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding_label/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/W_projection/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/b_projection/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_input_mask/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_bias/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_scale/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_bias/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_scale/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/beta1_power&quot;\\n  input: &quot;OptimizeLoss/train/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;OptimizeLoss/beta2_power/read&quot;\\n  input: &quot;OptimizeLoss/train/beta2&quot;\\n  input: &quot;^OptimizeLoss/train/update_Embedding_E/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/V_s/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/group_deps&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding_label/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/W_projection/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/b_projection/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_input_mask/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_bias/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_scale/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_bias/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_scale/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/beta2_power&quot;\\n  input: &quot;OptimizeLoss/train/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/update&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^OptimizeLoss/train/Assign&quot;\\n  input: &quot;^OptimizeLoss/train/Assign_1&quot;\\n  input: &quot;^OptimizeLoss/train/update_Embedding_E/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/V_s/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding/group_deps&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/Embedding_label/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/W_projection/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_embedding_projection/b_projection/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_input_mask/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_bias/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_multi_head_attention/layer_norm_scale/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_bias/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_layer_normalization0encoder_postion_wise_ff/layer_norm_scale/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/ApplyAdam&quot;\\n  input: &quot;^OptimizeLoss/train/update_sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/ApplyAdam&quot;\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train/value&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^OptimizeLoss/train/update&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Global_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/train&quot;\\n  op: &quot;AssignAdd&quot;\\n  input: &quot;Global_Step&quot;\\n  input: &quot;OptimizeLoss/train/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Global_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;OptimizeLoss/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;loss/add&quot;\\n  input: &quot;^OptimizeLoss/train&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@loss/add&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 62\\n          }\\n        }\\n        string_val: &quot;Embedding_E&quot;\\n        string_val: &quot;Epoch_Step&quot;\\n        string_val: &quot;Global_Step&quot;\\n        string_val: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n        string_val: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/beta1_power&quot;\\n        string_val: &quot;OptimizeLoss/beta2_power&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/input_mask/Adam&quot;\\n        string_val: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n        string_val: &quot;embedding_projection/Embedding&quot;\\n        string_val: &quot;embedding_projection/Embedding_label&quot;\\n        string_val: &quot;embedding_projection/W_projection&quot;\\n        string_val: &quot;embedding_projection/b_projection&quot;\\n        string_val: &quot;input_mask&quot;\\n        string_val: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n        string_val: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n        string_val: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n        string_val: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n        string_val: &quot;learning_rate&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 62\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;Embedding_E&quot;\\n  input: &quot;Epoch_Step&quot;\\n  input: &quot;Global_Step&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/beta1_power&quot;\\n  input: &quot;OptimizeLoss/beta2_power&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n  input: &quot;embedding_projection/Embedding&quot;\\n  input: &quot;embedding_projection/Embedding_label&quot;\\n  input: &quot;embedding_projection/W_projection&quot;\\n  input: &quot;embedding_projection/b_projection&quot;\\n  input: &quot;input_mask&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_INT32\\n        type: DT_INT32\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 62\\n          }\\n        }\\n        string_val: &quot;Embedding_E&quot;\\n        string_val: &quot;Epoch_Step&quot;\\n        string_val: &quot;Global_Step&quot;\\n        string_val: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n        string_val: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/beta1_power&quot;\\n        string_val: &quot;OptimizeLoss/beta2_power&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n        string_val: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/input_mask/Adam&quot;\\n        string_val: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n        string_val: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n        string_val: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n        string_val: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n        string_val: &quot;embedding_projection/Embedding&quot;\\n        string_val: &quot;embedding_projection/Embedding_label&quot;\\n        string_val: &quot;embedding_projection/W_projection&quot;\\n        string_val: &quot;embedding_projection/b_projection&quot;\\n        string_val: &quot;input_mask&quot;\\n        string_val: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n        string_val: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n        string_val: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n        string_val: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n        string_val: &quot;learning_rate&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n        string_val: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 62\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_INT32\\n        type: DT_INT32\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Embedding_E&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Epoch_Step&quot;\\n  input: &quot;save/RestoreV2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Epoch_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;Global_Step&quot;\\n  input: &quot;save/RestoreV2:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Global_Step&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam&quot;\\n  input: &quot;save/RestoreV2:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/Embedding_E/Adam_1&quot;\\n  input: &quot;save/RestoreV2:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam&quot;\\n  input: &quot;save/RestoreV2:5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1&quot;\\n  input: &quot;save/RestoreV2:6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam&quot;\\n  input: &quot;save/RestoreV2:7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1&quot;\\n  input: &quot;save/RestoreV2:8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam&quot;\\n  input: &quot;save/RestoreV2:9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1&quot;\\n  input: &quot;save/RestoreV2:10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam&quot;\\n  input: &quot;save/RestoreV2:11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_12&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1&quot;\\n  input: &quot;save/RestoreV2:12&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_13&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam&quot;\\n  input: &quot;save/RestoreV2:13&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_14&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1&quot;\\n  input: &quot;save/RestoreV2:14&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_15&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/beta1_power&quot;\\n  input: &quot;save/RestoreV2:15&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_16&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/beta2_power&quot;\\n  input: &quot;save/RestoreV2:16&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@Embedding_E&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_17&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam&quot;\\n  input: &quot;save/RestoreV2:17&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_18&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding/Adam_1&quot;\\n  input: &quot;save/RestoreV2:18&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_19&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam&quot;\\n  input: &quot;save/RestoreV2:19&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_20&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/Embedding_label/Adam_1&quot;\\n  input: &quot;save/RestoreV2:20&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_21&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam&quot;\\n  input: &quot;save/RestoreV2:21&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_22&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/W_projection/Adam_1&quot;\\n  input: &quot;save/RestoreV2:22&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_23&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam&quot;\\n  input: &quot;save/RestoreV2:23&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_24&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/embedding_projection/b_projection/Adam_1&quot;\\n  input: &quot;save/RestoreV2:24&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_25&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam&quot;\\n  input: &quot;save/RestoreV2:25&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_26&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/input_mask/Adam_1&quot;\\n  input: &quot;save/RestoreV2:26&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_27&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam&quot;\\n  input: &quot;save/RestoreV2:27&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_28&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1&quot;\\n  input: &quot;save/RestoreV2:28&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_29&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam&quot;\\n  input: &quot;save/RestoreV2:29&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_30&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1&quot;\\n  input: &quot;save/RestoreV2:30&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_31&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam&quot;\\n  input: &quot;save/RestoreV2:31&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_32&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1&quot;\\n  input: &quot;save/RestoreV2:32&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_33&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam&quot;\\n  input: &quot;save/RestoreV2:33&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_34&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1&quot;\\n  input: &quot;save/RestoreV2:34&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_35&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam&quot;\\n  input: &quot;save/RestoreV2:35&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_36&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1&quot;\\n  input: &quot;save/RestoreV2:36&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_37&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam&quot;\\n  input: &quot;save/RestoreV2:37&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_38&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1&quot;\\n  input: &quot;save/RestoreV2:38&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_39&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n  input: &quot;save/RestoreV2:39&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/V_s&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_40&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n  input: &quot;save/RestoreV2:40&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_41&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n  input: &quot;save/RestoreV2:41&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_42&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n  input: &quot;save/RestoreV2:42&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_43&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n  input: &quot;save/RestoreV2:43&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_44&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n  input: &quot;save/RestoreV2:44&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_45&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n  input: &quot;save/RestoreV2:45&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_46&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n  input: &quot;save/RestoreV2:46&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_47&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n  input: &quot;save/RestoreV2:47&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_48&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/Embedding&quot;\\n  input: &quot;save/RestoreV2:48&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_49&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/Embedding_label&quot;\\n  input: &quot;save/RestoreV2:49&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/Embedding_label&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_50&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/W_projection&quot;\\n  input: &quot;save/RestoreV2:50&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/W_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_51&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;embedding_projection/b_projection&quot;\\n  input: &quot;save/RestoreV2:51&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@embedding_projection/b_projection&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_52&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;input_mask&quot;\\n  input: &quot;save/RestoreV2:52&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_mask&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_53&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n  input: &quot;save/RestoreV2:53&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_54&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n  input: &quot;save/RestoreV2:54&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_multi_head_attention/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_55&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n  input: &quot;save/RestoreV2:55&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_56&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n  input: &quot;save/RestoreV2:56&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_normalization0encoder_postion_wise_ff/layer_norm_scale&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_57&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;learning_rate&quot;\\n  input: &quot;save/RestoreV2:57&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@learning_rate&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_58&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n  input: &quot;save/RestoreV2:58&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_59&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n  input: &quot;save/RestoreV2:59&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_60&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n  input: &quot;save/RestoreV2:60&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_61&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n  input: &quot;save/RestoreV2:61&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n  input: &quot;^save/Assign_12&quot;\\n  input: &quot;^save/Assign_13&quot;\\n  input: &quot;^save/Assign_14&quot;\\n  input: &quot;^save/Assign_15&quot;\\n  input: &quot;^save/Assign_16&quot;\\n  input: &quot;^save/Assign_17&quot;\\n  input: &quot;^save/Assign_18&quot;\\n  input: &quot;^save/Assign_19&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_20&quot;\\n  input: &quot;^save/Assign_21&quot;\\n  input: &quot;^save/Assign_22&quot;\\n  input: &quot;^save/Assign_23&quot;\\n  input: &quot;^save/Assign_24&quot;\\n  input: &quot;^save/Assign_25&quot;\\n  input: &quot;^save/Assign_26&quot;\\n  input: &quot;^save/Assign_27&quot;\\n  input: &quot;^save/Assign_28&quot;\\n  input: &quot;^save/Assign_29&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_30&quot;\\n  input: &quot;^save/Assign_31&quot;\\n  input: &quot;^save/Assign_32&quot;\\n  input: &quot;^save/Assign_33&quot;\\n  input: &quot;^save/Assign_34&quot;\\n  input: &quot;^save/Assign_35&quot;\\n  input: &quot;^save/Assign_36&quot;\\n  input: &quot;^save/Assign_37&quot;\\n  input: &quot;^save/Assign_38&quot;\\n  input: &quot;^save/Assign_39&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_40&quot;\\n  input: &quot;^save/Assign_41&quot;\\n  input: &quot;^save/Assign_42&quot;\\n  input: &quot;^save/Assign_43&quot;\\n  input: &quot;^save/Assign_44&quot;\\n  input: &quot;^save/Assign_45&quot;\\n  input: &quot;^save/Assign_46&quot;\\n  input: &quot;^save/Assign_47&quot;\\n  input: &quot;^save/Assign_48&quot;\\n  input: &quot;^save/Assign_49&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_50&quot;\\n  input: &quot;^save/Assign_51&quot;\\n  input: &quot;^save/Assign_52&quot;\\n  input: &quot;^save/Assign_53&quot;\\n  input: &quot;^save/Assign_54&quot;\\n  input: &quot;^save/Assign_55&quot;\\n  input: &quot;^save/Assign_56&quot;\\n  input: &quot;^save/Assign_57&quot;\\n  input: &quot;^save/Assign_58&quot;\\n  input: &quot;^save/Assign_59&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_60&quot;\\n  input: &quot;^save/Assign_61&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Embedding_E/Assign&quot;\\n  input: &quot;^Epoch_Step/Assign&quot;\\n  input: &quot;^Global_Step/Assign&quot;\\n  input: &quot;^OptimizeLoss/Embedding_E/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/Embedding_E/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/V_s/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/beta1_power/Assign&quot;\\n  input: &quot;^OptimizeLoss/beta2_power/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/Embedding/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/Embedding/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/Embedding_label/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/Embedding_label/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/W_projection/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/W_projection/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/b_projection/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/embedding_projection/b_projection/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/input_mask/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/input_mask/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_bias/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_multi_head_attention/layer_norm_scale/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Adam_1/Assign&quot;\\n  input: &quot;^OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam/Assign&quot;\\n  input: &quot;^OptimizeLoss/sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Adam_1/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/V_s/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense/bias/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense/kernel/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense_1/bias/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense_1/kernel/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense_2/bias/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense_2/kernel/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense_3/bias/Assign&quot;\\n  input: &quot;^base_mode_sub_layer_multi_head_attention_encoder0/dense_3/kernel/Assign&quot;\\n  input: &quot;^embedding_projection/Embedding/Assign&quot;\\n  input: &quot;^embedding_projection/Embedding_label/Assign&quot;\\n  input: &quot;^embedding_projection/W_projection/Assign&quot;\\n  input: &quot;^embedding_projection/b_projection/Assign&quot;\\n  input: &quot;^input_mask/Assign&quot;\\n  input: &quot;^layer_normalization0encoder_multi_head_attention/layer_norm_bias/Assign&quot;\\n  input: &quot;^layer_normalization0encoder_multi_head_attention/layer_norm_scale/Assign&quot;\\n  input: &quot;^layer_normalization0encoder_postion_wise_ff/layer_norm_bias/Assign&quot;\\n  input: &quot;^layer_normalization0encoder_postion_wise_ff/layer_norm_scale/Assign&quot;\\n  input: &quot;^learning_rate/Assign&quot;\\n  input: &quot;^sub_layer_postion_wise_feed_forwardencoder0/conv1/bias/Assign&quot;\\n  input: &quot;^sub_layer_postion_wise_feed_forwardencoder0/conv1/kernel/Assign&quot;\\n  input: &quot;^sub_layer_postion_wise_feed_forwardencoder0/conv2/bias/Assign&quot;\\n  input: &quot;^sub_layer_postion_wise_feed_forwardencoder0/conv2/kernel/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.029598204821446816&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_fn.started.\n",
      "MultiHeadAttention.self.dropout_rate: Tensor(\"base_mode_sub_layer_multi_head_attention_encoder0/sub:0\", dtype=float32)\n",
      "scaled_dot_product_attention_batch.===============================================================>mask is not none? False\n",
      "dot_product:====================================================================================> Tensor(\"base_mode_sub_layer_multi_head_attention_encoder0/MatMul_1:0\", shape=(1, 8, 6, 64), dtype=float32)\n",
      "self.sequence_length: 6\n",
      "@@@========================>layer_input: Tensor(\"Add_1:0\", shape=(1, 6, 512), dtype=float32) ;layer_output: Tensor(\"base_mode_sub_layer_multi_head_attention_encoder0/dense_3/BiasAdd:0\", shape=(1, 6, 512), dtype=float32)\n",
      "LayerNormResidualConnection.use_residual_conn: False\n",
      "layer_normalization:==================>variable_scope: layer_normalization0encoder_multi_head_attention\n",
      "output_conv1: Tensor(\"sub_layer_postion_wise_feed_forwardencoder0/transpose:0\", shape=(1, 6, 2048, 1), dtype=float32)\n",
      "@@@========================>layer_input: Tensor(\"layer_normalization0encoder_multi_head_attention/add_1:0\", shape=(1, 6, 512), dtype=float32) ;layer_output: Tensor(\"sub_layer_postion_wise_feed_forwardencoder0/Squeeze:0\", shape=(6, 512), dtype=float32)\n",
      "LayerNormResidualConnection.use_residual_conn: True\n",
      "layer_normalization:==================>variable_scope: layer_normalization0encoder_postion_wise_ff\n",
      "encoder_fn. 0 .Q: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32) ;K_s: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32)\n",
      "encoder_fn.ended.Q: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32) ;K_s: Tensor(\"layer_normalization0encoder_postion_wise_ff/add_1:0\", shape=(1, 6, 512), dtype=float32) ;time spent: 0.3507051467895508\n",
      "logits: Tensor(\"output/add:0\", shape=(1, 11), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from checkpoint_transformer/sequence_reverse/model.ckpt-90\n",
      "=================restored.\n",
      "0 label_list_original as input x: [3, 4, 5, 2, 6] prediction: [5] ;label: [6]\n",
      "1 label_list_original as input x: [3, 5, 4, 2, 6] prediction: [5] ;label: [6]\n",
      "2 label_list_original as input x: [5, 3, 2, 4, 6] prediction: [3] ;label: [6]\n",
      "3 label_list_original as input x: [3, 6, 2, 5, 4] prediction: [6] ;label: [5]\n",
      "4 label_list_original as input x: [5, 3, 2, 6, 4] prediction: [6] ;label: [6]\n",
      "5 label_list_original as input x: [4, 6, 5, 2, 3] prediction: [5] ;label: [3]\n",
      "6 label_list_original as input x: [4, 6, 2, 3, 5] prediction: [6] ;label: [5]\n",
      "7 label_list_original as input x: [4, 6, 3, 2, 5] prediction: [4] ;label: [5]\n",
      "8 label_list_original as input x: [5, 4, 2, 6, 3] prediction: [6] ;label: [6]\n",
      "9 label_list_original as input x: [2, 3, 6, 5, 4] prediction: [6] ;label: [5]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "test_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO#1: add tensorboard to visualize training loss, computational graph.\n",
    "(Suggestion):\n",
    "- 1. Define a log_path, create a `writer` to save TF's events.\n",
    "- 2. Visualize to see what is the current computational graph.\n",
    "- 3. Create `summary` objects to store weights.\n",
    "- 4. Add summary into the `writer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO#2: (at home) change from the toy dataset to the real IMDB dataset.\n",
    "- This is how you get the IMDB dataset:\n",
    "```\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data('./imdb.npz', \n",
    "                                                     num_words=5000, # get 5000 words\n",
    "                                                     skip_top = 0,   # No skipping\n",
    "                                                     maxlen=0,       # No maximum length\n",
    "                                                     start_char=1,   # starting char\n",
    "                                                     oov_char=2,     # out-of-vocabulary\n",
    "                                                     index_from=3)   # real index\n",
    "```\n",
    "- Check the dataset:\n",
    "```\n",
    "print(\"X.train: %s, y.train: %s, X.test: %s, y.test: %s\" %(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "```\n",
    "\n",
    "- Exploring the dataset:\n",
    "\n",
    "```\n",
    "# Get index of all vocabulary\n",
    "vocab_idx = imdb.get_word_index()\n",
    "# Let see how one represented document looks like\n",
    "print (X_train[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions: \n",
    "What you should know after this:\n",
    "- 1. Know what is the architecture of the Transformer model.\n",
    "- 2. Know how to do the training and testing for classifications on a toy dataset.\n",
    "- 3. Plus, you will have a chance to work more on this model inside BERT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
