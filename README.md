# 01. Preparing environments
There are three different ways to follow the course for the hands-on part. 
You're recommended to use the **Jupyter Lab**  but other backup options are also available (i.e., Google Colab and HPC2N). 
## Jupyter Lab (recommended):
How to install: see [README](guides/README.md).

## Google Colab (optional): 
See [Howto_GoogleColab](guides/Howto_GoogleColab.md).

## HPC2N (optional): 
See [instructions](guides/Install-HPC2N.md) for how to install and run from command line (no Jupyter Lab) at HPC2N.

# 02. Datasets:
We mostly will work with:
- The MNIST dataset for image processing 
- The IMDB reviews for NLP tasks.

# 03. Labs (tentative):
- Tensorflow and Tensorboard: basics
- Tensorflow: Linear Regression with constraints during optimization.
- RNN: Language Modelling task.
- ETNLP: Exploring different word embeddings.                                                                                                               
- Transformers: sentiment classification tasks.
- ELMO and BERT: sentiment classification tasks.
- GANs: Generative Adversarial Networks